TUGAS PERTEMUAN 5
NAMA	: MAYA NURROHMAH
NPM		: 41155050210019
KELAS	: INF_A1

1.	K-Nearest Neighbours (KNN). Lakukan praktik dari https://youtu.be/4zARMcgc7hA?si=x6RoHQXFF4NY76X8 , buat screenshot dengan nama kalian pada coding, kumpulkan dalam bentuk pdf, dari kegiatan ini:
1)	Persiapan sample dataset
 ![image](https://github.com/user-attachments/assets/47d2247c-e07e-428b-84b1-cc778f8dafe5)

2)	Visualisasi dataset
 ![image](https://github.com/user-attachments/assets/20c45d3d-c887-4a7f-a6f6-f347019d8392)


3)	Pengantar classification dengan K-Nearest Neighbours | KNN

Kita akan melakukan KNN untuk melakukan klasifikasi jenis kelamin berdasrkan data tinggi dan berat badan. Sesuai dengan Namanya model machine learning satu ini akan melakukan prediksi dalam kasus ini adalah prediksi gender atau prediksi jenis kelamin berdasarkan kemiripan karakteristik dengan dataset yang kita miliki.

4)	Preprocessing dataset dengan Label Binarizer
 ![image](https://github.com/user-attachments/assets/58b961d8-0644-4cea-811c-ccee5b3f36d3)
![image](https://github.com/user-attachments/assets/6da6c3ff-d714-4463-b5a2-ae706a973957)

5)	Training KNN Classification Model
 ![image](https://github.com/user-attachments/assets/715c1ba1-1269-4e5b-b748-07ee8e631b8b)

6)	Prediksi dengan KNN Classification Model
 ![image](https://github.com/user-attachments/assets/2f20032c-0e6f-45a0-9c88-6e33d91f61ba)


7)	Visualisasi Nearest Neighbours
 ![image](https://github.com/user-attachments/assets/111f748b-da1c-45d4-b55b-267e26de2f4b)

8)	Kalkulasi jarak dengan Euclidean Distance
 ![image](https://github.com/user-attachments/assets/c1396b81-95ea-484f-b92c-127cc031bd89)

 ![image](https://github.com/user-attachments/assets/6fb2110c-e081-4748-82ac-6176a57fdd84)

9)	Evaluasi KNN Classification Model | Persiapan testing set
 ![image](https://github.com/user-attachments/assets/1362800e-74af-4f65-bab1-b2beffef4de7)

10)	 Evaluasi model dengan accuracy score
 ![image](https://github.com/user-attachments/assets/4a6c03c5-8fb7-4563-8c69-4934af5e2e42)

11)	 Evaluasi model dengan precision score
![image](https://github.com/user-attachments/assets/995a0ade-1f7f-40a1-9c90-6fa529b3cb01)
 
12)	 Evaluasi model dengan recall score
 ![image](https://github.com/user-attachments/assets/71b5bfa1-ee55-4c0d-9e87-2521a8e8623e)

13)	 Evaluasi model dengan F1 score
![image](https://github.com/user-attachments/assets/df67f5b0-08a0-4f4e-b486-ad458171ed22)
 
14)	 Evaluasi model dengan classification report
 ![image](https://github.com/user-attachments/assets/400f46ea-02fa-434a-8800-b538d6ac4340)

15)	 Evaluasi model dengan Mathews Correlation Coefficient
 ![image](https://github.com/user-attachments/assets/60dd7fd1-0ed4-4c02-aee2-4d2b023cdf65)

2.	Support Vector Machine (SVM). Lakukan praktik dari https://youtu.be/z69XYXpvVrE?si=KR_hDSlwjGIMcT0w , buat screenshot dengan nama kalian pada coding, kumpulkan dalam bentuk pdf, dari kegiatan ini:
1)	Pengenalan Decision Boundary & Hyperplane
   
Contoh kasus :
![image](https://github.com/user-attachments/assets/09f871a2-a045-43b6-86d8-3f3356b65e39)





Pada Gambar diatas kita dihadapkan pada sebuah kasus klasifikasi dimana terdapat dua buah class, sebut saja class hitam dan putih. Pada kasus ini juga terdapat dua buah fitur yaitu x1 dan x2, pada kasus disini kita diminta untuk menarik suatu garis lurus atau garis linear yang dapat memisahkan kedua class ini. Dalam classification task pemisah atau pembatas antar class ini juga sering dikenal dengan istilan Decision Boundary, Semisal saja kita disini dihadapkan pada tiga pilihan garis linier yaitu H1,H2 dan H3. Dari ketiga garis linear ini manakah yang paling baik untuk digunakan sebagai Decision Boundary atau pemisah antar dua class yang kita miliki?. Jawabannya adalah H3 alasanya adalah karena H3 memiliki margin yang lebih besar bila dibandingkan dengan H2
Beberapa Terminologi Dasar
Terminologi yang pertama adalah terminology hyperplane, Terminologi Hyperplane ini merupakan terminology yang umum digunakan dalam svm untuk merepresentasikan Decision Boundary.
Dalam Kasus diatas karena kita dihadapkan pada dua fitur maka kita emeiliki floating dua dimensi, oleh karenanya decision boundry yang kita peroleh berupa suatu garis dan dalam kasus ini berupa garis lurus atau linear, tetapi ketika kita hanya memiliki satu fitur saja maka decision boundary akan berupa titik atau nilai threshold, lalu ketika terdapat 3 picture maka decision boundary nya berupa sebuah bidang datar atau biasa dikenal dengan istilah flying, ketika terdapat empat atau lebih picture maka pemisah antar classnya bidang multidimensi atau biasa dikenal dengan istilah hyperplane. 

2)	Pengenalan Support Vector & Maximum Margin
   
 ![image](https://github.com/user-attachments/assets/6f0095ab-3413-4cc3-b04e-f25f1acf3c56)

Margin ditentukan berdasarkan jarak terdekat antara Decision Boundary dengan anggota dari class yang ingin dipisahkan.
Pada gambar diatas terdapat dua buah picture yaitu x1 dan x2, lalu pada gambar diatas kita memiliki sebuah decision boundary berupa garis linear berwarna merah yang digunakan untuk memisahkan kedua class yang kita miliki, garis linear merah ini merupakan decision boundary yang memisahkan class biru dengan class hijau dan area yang diarsir dengan warna kuning itulah yang dinamakn dengan margin. Margin diperoleh berdasarkan jarak terdekat antara decision boundary dengan anggota dari class yang ingin dipisahkan, dan setiap anggota class yang berperan untuk menentukan margin dikenal sebagai super vector.

3)	Pengenalan kondisi Linearly Inseparable dan Kernel Tricks
   ![image](https://github.com/user-attachments/assets/a2ef4050-913e-4a09-ba00-c93e9f1a669a)

Pada kasus gambar diatas terdapat dua buah class yaitu class titik dan class x, dsini juga terdapat dua buah picture sehingga ketika dilakukan floating kita akan mendaoatkan floating dua dimensi semacam gambar diatas yang sebelah kiri. Nah pada kasus kali ini tidak memungkinkan bagi kita untuk menarik garis linear sebagai decision boundary kondisi semacam ini dikenal dengan istilah Linearly Inseperable. untuk  mengatasi kondisi semacam ini svm akan memproyeksi data yang ada ke dimensi yang lebih tinggi, artinya bila data yang sebelumnya berada dalam dua dimensi maka svm akan memproyeksikannya ke 3 dimensi seperti Nampak pada floating di sisi sebelah kanan.
Upaya untuk mempoyeksikan sekumpulan data kedimensi yang lebih tinggi tentunya akan berimbas pada kenaikan beban komputasi, nah untuk menjawab kebutuhan semacam ini svm menawarkan Teknik yang sangat efisien yang dikenal dengan istilah Kernel Tricks.

4)	Pengenalan MNIST Handwritten Digits Dataset
 
![image](https://github.com/user-attachments/assets/b9be23f9-1276-4808-a500-7588e3804ffe)
![image](https://github.com/user-attachments/assets/3572c9e8-7176-4f3b-9ef2-f96ad782e41a)

5)	Klasifikasi dengan Support Vector Classifier | SVC
 ![image](https://github.com/user-attachments/assets/07ee4ec7-56d4-480d-a0ee-e978c6652b47)

6)	Hyperparameter Tuning dengan Grid Search
![image](https://github.com/user-attachments/assets/c0e9c925-087a-4612-8d32-b6cc9a328551)
 
![image](https://github.com/user-attachments/assets/d116e3a9-7e1e-4995-bc26-2ba5c420f595)
 



7)	Evaluasi Model
 
![image](https://github.com/user-attachments/assets/fd0de3e0-6785-4266-8668-672a8e4ea344)

